{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83cba679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm ges\n",
      "../Adult_Analysis/ges/PP\\Adult_ges_pp_1.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "arr does not include protected attributes in the index. Check if this got dropped or prot_attr is formatted incorrectly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\aif360\\sklearn\\utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(arr, prot_attr, ensure_binary)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprot_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             raise TypeError(\"arr does not include protected attributes in the \"\n\u001b[0m\u001b[0;32m     90\u001b[0m                             \u001b[1;34m\"index. Check if this got dropped or prot_attr is \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   6127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6128\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6129\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'None of [None] are in the columns'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 249\u001b[0m\n\u001b[0;32m    247\u001b[0m     mitigator \u001b[38;5;241m=\u001b[39m CalibratedEqualizedOdds(prot_attr\u001b[38;5;241m=\u001b[39mA2, cost_constraint\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfpr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    248\u001b[0m     mitigator\u001b[38;5;241m.\u001b[39mfit(y_prob,Y2)\n\u001b[1;32m--> 249\u001b[0m     preds_new \u001b[38;5;241m=\u001b[39m \u001b[43mmitigator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_prob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m acc_temp \u001b[38;5;241m=\u001b[39m accuracy_score(Y2,preds_new)\n\u001b[0;32m    251\u001b[0m f1_temp \u001b[38;5;241m=\u001b[39m f1_score(Y2,preds_new)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\aif360\\sklearn\\postprocessing\\calibrated_equalized_odds.py:199\u001b[0m, in \u001b[0;36mCalibratedEqualizedOdds.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    189\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict class labels for the given scores.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m        numpy.ndarray: Predicted class label per sample.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[scores\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\aif360\\sklearn\\postprocessing\\calibrated_equalized_odds.py:169\u001b[0m, in \u001b[0;36mCalibratedEqualizedOdds.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    166\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmix_rates_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    167\u001b[0m rng \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[1;32m--> 169\u001b[0m groups, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprot_attr_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mset\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(groups)) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups_):\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe protected groups from X:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mdo not \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    172\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch those from the training set:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    173\u001b[0m                              np\u001b[38;5;241m.\u001b[39munique(groups), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups_))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\aif360\\sklearn\\utils.py:89\u001b[0m, in \u001b[0;36mcheck_groups\u001b[1;34m(arr, prot_attr, ensure_binary)\u001b[0m\n\u001b[0;32m     87\u001b[0m         groups \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mset_index(prot_attr)\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 89\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marr does not include protected attributes in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex. Check if this got dropped or prot_attr is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     91\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformatted incorrectly.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     92\u001b[0m prot_attr \u001b[38;5;241m=\u001b[39m groups\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m     93\u001b[0m groups \u001b[38;5;241m=\u001b[39m groups\u001b[38;5;241m.\u001b[39mto_flat_index()\n",
      "\u001b[1;31mTypeError\u001b[0m: arr does not include protected attributes in the index. Check if this got dropped or prot_attr is formatted incorrectly."
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys,os\n",
    "sys.path.append(\"./subjects/\")\n",
    "subject_path = os.path.join(os.getcwd(), '..', 'subjects')\n",
    "sys.path.append(os.path.abspath(subject_path))\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import random, math\n",
    "import tensorflow_probability as tfb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics.pairwise import  euclidean_distances\n",
    "from Utils_Functions import KLdivergence\n",
    "from sklearn.feature_selection import SelectKBest, SelectFpr,SelectPercentile \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from aif360.sklearn.metrics import equal_opportunity_difference,average_odds_difference\n",
    "from Utils_Functions import generate_dataset, eod\n",
    "import glob\n",
    "import re\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from aif360.sklearn.postprocessing import CalibratedEqualizedOdds\n",
    "def generate_dataset_shift(data, graph, edges, sens_index,priv_group, unpriv_group):\n",
    "\n",
    "    dataset_types = [str(data[i].dtype) for i in data.columns]\n",
    "    succ_generated = 0\n",
    "    generation_coef = 1\n",
    "    graph_dic ={}\n",
    "    for i in graph.columns[1:]:\n",
    "        if np.where(graph[i])[0].shape[0]==0:\n",
    "            graph_dic[i]=None\n",
    "        else:\n",
    "            graph_dic[i]= graph['Unnamed: 0'][np.where(graph[i])[0]].values\n",
    "\n",
    "    final_df = pd.DataFrame(columns = data.columns) \n",
    "    trial = 0\n",
    "    not_interesting = False\n",
    "    while final_df.shape[0]<data.shape[0]:\n",
    "\n",
    "        if trial > 20:\n",
    "            not_interesting = True\n",
    "            return None , False\n",
    "        df_new_dic ={}\n",
    "        for edge in graph.sum().index[np.where(graph.sum()==0)[0]]:\n",
    "            df_new_dic[edge] = np.random.choice(np.unique(data[edge]), size = data.shape[0]*generation_coef) \n",
    "\n",
    "        statring_atts = graph.sum().index[np.where(graph.sum()==0)[0]]\n",
    "        \n",
    "        while statring_atts.shape[0] != graph['Unnamed: 0'].shape[0]:\n",
    "            \n",
    "            for att in graph_dic.keys():\n",
    "                if att not in statring_atts:\n",
    "                    if 0 in  [1 if graph_dic[att][i] in statring_atts else 0 for i in range(graph_dic[att].shape[0])]:\n",
    "\n",
    "                        continue\n",
    "                    else:\n",
    "                        edge_logits = 0\n",
    "                        \n",
    "                        for cause in graph_dic[att]:\n",
    "                            edge_logits += (edges[cause+att] * df_new_dic[cause])\n",
    "                        if np.unique(data[att]).shape[0]==2:\n",
    "                            df_new_dic[att] =  tfb.distributions.Bernoulli(logits=edge_logits + edges[att+'0'] ).sample().numpy()\n",
    "                        elif 'float' in dataset_types[np.where(data.columns==att)[0][0]]:\n",
    "\n",
    "                            df_new_dic[att] =  tfb.distributions.Normal(loc=(edge_logits+ edges[att+'0']), scale= edges['sigma_h']).sample().numpy()\n",
    "                        \n",
    "                        else:    \n",
    "                            df_new_dic[att] =  tfb.distributions.Poisson(rate=tf.exp(edge_logits+ edges[att+'0']) ).sample().numpy()  \n",
    "\n",
    "                        statring_atts = np.append(statring_atts,att) \n",
    "\n",
    "        new_df = pd.DataFrame(columns = data.columns)\n",
    "        for col in new_df.columns:\n",
    "            new_df[col] = df_new_dic[col]\n",
    "        \n",
    "        ind_inf = np.unique(np.where(new_df>data.max())[0])\n",
    "        new_df.drop(ind_inf,axis=0,inplace=True)\n",
    "        for col in range(new_df.columns.shape[0]):\n",
    "            new_df[new_df.columns[col]]=new_df[new_df.columns[col]].astype(dataset_types[col])\n",
    "        if new_df.shape[0]<1:\n",
    "            return None , False\n",
    "        X2 = new_df.to_numpy()[:,:-1]\n",
    "        Y2 = new_df.to_numpy()[:,-1]\n",
    "        #dist = euclidean_distances(X2, centroids)\n",
    "        #succ_generated += new_df.iloc[np.where((ave_dist>=dist).sum(1)>0)].shape[0]\n",
    "        final_df = pd.concat([final_df,new_df]).reset_index(drop=True)\n",
    "        final_df = final_df.drop_duplicates()\n",
    "\n",
    "\n",
    "            \n",
    "        trial += 1\n",
    "   \n",
    "    #final_df = final_df.astype(int)\n",
    "    Y2 = final_df.to_numpy()[:,-1]\n",
    "    if (Y2.sum()/Y2.shape[0]< 0.06) or (Y2.sum()/Y2.shape[0]> 0.95):\n",
    "        return None,  False\n",
    "    if priv_group not in final_df[final_df.columns[sens_index]].values or unpriv_group not in final_df[final_df.columns[sens_index]].values:\n",
    "        return None,  False\n",
    "\n",
    "    return final_df, True\n",
    "Practice = 'CEO'\n",
    "#dataset ='Bank'\n",
    "for dataset in ['Adult']:\n",
    "    if dataset == 'Adult':\n",
    "        sens_index = 7\n",
    "        priv_group = 1\n",
    "        unpriv_group = 0\n",
    "        data_file_name = 'adult_org-Copy1.csv'\n",
    "        alg_list = ['ges','simy']\n",
    "        \n",
    "    if dataset == 'Compas':\n",
    "        sens_index = 1\n",
    "        priv_group = 1\n",
    "        unpriv_group = 0\n",
    "        data_file_name = 'compas-Copy1'\n",
    "        alg_list = ['ges','pc']\n",
    "        \n",
    "    if dataset == 'Bank':\n",
    "        sens_index = 0\n",
    "        priv_group = 5\n",
    "        unpriv_group = 3\n",
    "        data_file_name = 'bank'\n",
    "        alg_list = ['ges']\n",
    "        \n",
    "    if dataset == 'Heart':\n",
    "        sens_index = 0\n",
    "        priv_group = 1\n",
    "        unpriv_group = 0 \n",
    "        data_file_name = 'heart_processed_1'\n",
    "        alg_list = ['ges']\n",
    "        \n",
    "    if dataset == 'Law':\n",
    "        sens_index = 1\n",
    "        priv_group = 1\n",
    "        unpriv_group = 0\n",
    "        data_file_name = 'law.csv'\n",
    "        alg_list = ['ges','simy']\n",
    "\n",
    "    if dataset == 'Student':\n",
    "        sens_index = 0\n",
    "        priv_group = 1\n",
    "        unpriv_group = 0 \n",
    "        alg_list = ['simy','pc']\n",
    "        data_file_name = 'students-processed_2'\n",
    "        \n",
    "    df = pd.read_csv('../subjects/datasets/'+data_file_name)\n",
    "    df =  df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    X1 = df.to_numpy()[:,:-1]\n",
    "    Y1 = df.to_numpy()[:,-1].astype(int)\n",
    "\n",
    "    \n",
    "    for Algorithm in alg_list:\n",
    "        print('Algorithm', Algorithm)\n",
    "        for edge_list_filename in glob.glob('../'+dataset+'_Analysis/'+Algorithm+'/PP/*.csv'):\n",
    "            print(edge_list_filename)\n",
    "            file_num = int(re.findall(r'\\d+', edge_list_filename.split('/')[-1])[0])\n",
    "            RQ1_res = np.load('../'+dataset+'_Analysis/RQ1/'+dataset+'_'+Algorithm+'_RQ1_results.npy')\n",
    "            if RQ1_res[np.where(RQ1_res[:,1].astype(int)==file_num)[0]][0][2].astype(float)==0.0:\n",
    "                print('No',file_num)\n",
    "                continue\n",
    "            try:\n",
    "                graph_filename = '../'+dataset+'_Analysis/'+Algorithm+'/DAGs/'+dataset+'_'+Algorithm+'_DAG_{file_num}.csv'.format(file_num=file_num)\n",
    "                graph = pd.read_csv(graph_filename)\n",
    "                #edge_list_filename = './'+dataset+'_Analysis/'+Algorithm+'/PP/'+dataset+'_'+Algorithm+'_pp_{file_num}.csv'.format(file_num=file_num)\n",
    "                edges_list = pd.read_csv(edge_list_filename)\n",
    "                if 'first_pf0' not in edges_list.columns and 'label0' not in edges_list.columns and 'G30' not in edges_list.columns and 'y0' not in edges_list.columns:\n",
    "                    continue \n",
    "                if dataset=='Bank' and Algorithm=='simy':\n",
    "                    graph.columns = [i.replace('1','') for i in graph.columns]\n",
    "                    graph[graph.columns[0]] = [i.replace('1','') for i in graph[graph.columns[0]]]\n",
    "                    edges_list.columns = [i.replace('1','') for i in edges_list.columns]\n",
    "                edges_list = edges_list[edges_list.columns[1:-1]]\n",
    "\n",
    "            except:\n",
    "                print('Not a DAG! ',file_num)\n",
    "                continue\n",
    "\n",
    "            X1_coef = edges_list.to_numpy()\n",
    "            KMean_coef = KMeans(n_clusters=10)\n",
    "            KMean_coef.fit(X1_coef)\n",
    "            \n",
    "            mitigator_final_EOD=[]\n",
    "            None_model_final_EOD = []\n",
    "            mitigator_final_AOD=[]\n",
    "            None_model_final_AOD = []\n",
    "\n",
    "            for i in range(KMean_coef.n_clusters):\n",
    "                #print('Coef ',i)\n",
    "                weights_ind = np.random.choice(np.where(KMean_coef.labels_==i)[0])\n",
    "                edges = edges_list.iloc[weights_ind]\n",
    "\n",
    "                if dataset=='Law':\n",
    "                    edges['first_pf0']+=1\n",
    "                elif dataset=='Bank':\n",
    "                    edges['label0']+=1\n",
    "                elif dataset=='Heart':\n",
    "                    edges['label0']+=1\n",
    "                elif dataset=='Student':\n",
    "                    edges['G30']+=1\n",
    "                else:\n",
    "                    edges['y0']+=1\n",
    "                #print(file_num,weights_ind)\n",
    "                mitigator_EOD=[]\n",
    "                mitigator_AOD=[]\n",
    "                None_model = []\n",
    "                for j in range(10):\n",
    "                    final_df, status = generate_dataset_shift(df, graph, edges,sens_index, priv_group, unpriv_group)\n",
    "\n",
    "                    if status==False:\n",
    "                        continue\n",
    "\n",
    "                    X2 = final_df.to_numpy()[:,:-1]\n",
    "                    Y2 = final_df.to_numpy()[:,-1].astype(int)\n",
    "                    A2 = X2[:,sens_index]\n",
    "\n",
    "                    if priv_group not in A2 or unpriv_group not in A2:\n",
    "                        print('No sens group')\n",
    "                        continue\n",
    "                    model = LogisticRegression()\n",
    "                    model.fit(X2,Y2)\n",
    "                    \n",
    "                    preds_None = model.predict(X2)\n",
    "                    acc_None = accuracy_score(Y2,preds_None)\n",
    "                    f1_None = f1_score(Y2,preds_None)\n",
    "                    AOD_None = round(average_odds_difference(Y2, preds_None,prot_attr=A2,priv_group=priv_group ),3)\n",
    "                    EOD_None = eod(Y2, preds_None,sens=A2, priv=priv_group, unpriv=unpriv_group)        \n",
    "                    None_model.append([EOD_None,acc_None,f1_None])\n",
    "                    y_prob = model.predict_proba(X2)\n",
    "                    if Practice == 'TO':\n",
    "                    #print('Success rate DAG', file_num, succ_rate)\n",
    "                        mitigator = ThresholdOptimizer(\n",
    "                            estimator=model,\n",
    "                            constraints=\"equalized_odds\",   # or \"demographic_parity\"\n",
    "                            prefit=True,\n",
    "                            predict_method=\"predict_proba\")\n",
    "                        mitigator.fit(X2,Y2, sensitive_features=A2)\n",
    "                        preds_new = mitigator.predict(X2,sensitive_features=A2)\n",
    "                    if Practice == 'CEO':\n",
    "                        mitigator = CalibratedEqualizedOdds(prot_attr=A2, cost_constraint='fpr')\n",
    "                        mitigator.fit(y_prob,Y2)\n",
    "                        preds_new = mitigator.predict(y_prob)\n",
    "                    acc_temp = accuracy_score(Y2,preds_new)\n",
    "                    f1_temp = f1_score(Y2,preds_new)\n",
    "                    AOD = round(average_odds_difference(Y2, preds_new,prot_attr=A2,priv_group=priv_group ),3)\n",
    "                    EOD = eod(Y2, preds_new,sens=A2, priv=priv_group, unpriv=unpriv_group)\n",
    "                    acc_diff = round(acc_temp - acc_None,2)\n",
    "                    f1_diff = round(f1_temp- f1_None,2)\n",
    "                    EOD_diff = EOD - EOD_None\n",
    "                    AOD_diff = AOD - AOD_None\n",
    "                    EOD_diff_abs = abs(EOD) - abs(EOD_None)\n",
    "                    AOD_diff_abs = abs(AOD) - abs(AOD_None)\n",
    "\n",
    "                    input(EOD_diff)\n",
    "                    \n",
    "                    mitigator_EOD.append([ EOD,EOD_None,EOD_diff,EOD_diff_abs, acc_diff, f1_diff])\n",
    "                    mitigator_AOD.append([ AOD,AOD_None,AOD_diff,AOD_diff_abs, acc_diff, f1_diff])\n",
    "\n",
    "\n",
    "\n",
    "                mitigator_final_EOD.append(np.mean(mitigator_EOD,axis=0))\n",
    "                mitigator_final_AOD.append(np.mean(mitigator_AOD,axis=0)) \n",
    "                \n",
    "            np.save('../'+dataset+'_Analysis/RQ4/'+Algorithm+'_'+Practice +'_'+ str(file_num)+'.npy',mitigator_final_EOD)\n",
    "            np.save('../'+dataset+'_Analysis/RQ4/'+Algorithm+'_'+Practice +'_' + str(file_num)+'.npy',mitigator_final_AOD)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "300cd7f5-fd5c-4741-95f9-a699de0214fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "arr does not include protected attributes in the index. Check if this got dropped or prot_attr is formatted incorrectly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\aif360\\sklearn\\utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(arr, prot_attr, ensure_binary)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprot_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             raise TypeError(\"arr does not include protected attributes in the \"\n\u001b[0m\u001b[0;32m     90\u001b[0m                             \u001b[1;34m\"index. Check if this got dropped or prot_attr is \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   6127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6128\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6129\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'None of [None] are in the columns'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmitigator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_prob\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\aif360\\sklearn\\postprocessing\\calibrated_equalized_odds.py:199\u001b[0m, in \u001b[0;36mCalibratedEqualizedOdds.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    189\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict class labels for the given scores.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m        numpy.ndarray: Predicted class label per sample.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[scores\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\aif360\\sklearn\\postprocessing\\calibrated_equalized_odds.py:169\u001b[0m, in \u001b[0;36mCalibratedEqualizedOdds.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    166\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmix_rates_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    167\u001b[0m rng \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[1;32m--> 169\u001b[0m groups, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprot_attr_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mset\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(groups)) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups_):\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe protected groups from X:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mdo not \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    172\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch those from the training set:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    173\u001b[0m                              np\u001b[38;5;241m.\u001b[39munique(groups), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups_))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\aif360\\sklearn\\utils.py:89\u001b[0m, in \u001b[0;36mcheck_groups\u001b[1;34m(arr, prot_attr, ensure_binary)\u001b[0m\n\u001b[0;32m     87\u001b[0m         groups \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mset_index(prot_attr)\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 89\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marr does not include protected attributes in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex. Check if this got dropped or prot_attr is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     91\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformatted incorrectly.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     92\u001b[0m prot_attr \u001b[38;5;241m=\u001b[39m groups\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m     93\u001b[0m groups \u001b[38;5;241m=\u001b[39m groups\u001b[38;5;241m.\u001b[39mto_flat_index()\n",
      "\u001b[1;31mTypeError\u001b[0m: arr does not include protected attributes in the index. Check if this got dropped or prot_attr is formatted incorrectly."
     ]
    }
   ],
   "source": [
    "mitigator.predict(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3999d08c-2535-4a0a-8531-80a6da3bd6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41662, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X2).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e71a29f0-2083-4376-a4ef-f208b219bfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41662,), (41662, 10), (41662,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2.shape, X2.shape, A2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "931fbb26-77e3-4706-82a7-7a17e6493f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2[:,sens_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a80be7f6-7701-4b37-8971-d5543491ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_new = mitigator.predict(X2,sensitive_features=A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9b647-d652-4d8c-918c-df10448df7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
