{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "129de982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAG  532\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dags_num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 138\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mAlgorithm\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/PP/Bank_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mAlgorithm\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_DAG_\u001b[39m\u001b[38;5;132;01m{file_num}\u001b[39;00m\u001b[38;5;124m.stan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(file_num\u001b[38;5;241m=\u001b[39mfile_num),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    137\u001b[0m             file\u001b[38;5;241m.\u001b[39mwritelines(data_to_file)\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mdags_num\u001b[49m \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m16\u001b[39m:\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m#     print('Python code -----------------')\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m#     for edge in graph.sum().index[np.where(graph.sum()==0)[0]]:\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m#         print('{edge}  = df[\\'{edge}\\'].values'.format(edge = edge))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m#     for feat in graph.columns[1:]:\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m#         print('new_df[\\'{edge}\\']  = {edge}'.format(edge=feat))\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dags_num' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "Algorithm = 'simy'\n",
    "\n",
    "data = pd.read_csv('../subjects/datasets/bank')\n",
    "dataset_types = [str(data[i].dtype) for i in data.columns]\n",
    "dags_num = 0\n",
    "for file_num in range(1,1000):\n",
    "    if Algorithm == 'simy':\n",
    "        file_num = np.random.randint(1,1000)\n",
    "    not_a_DAG = False\n",
    "    graph = pd.read_csv('./'+Algorithm+'/DAGs/Bank_'+Algorithm+'_DAG_{file_num}.csv'.format(file_num=file_num))\n",
    "    graph.columns =  [graph.columns[0]]+ data.columns.to_list()\n",
    "    graph[graph.columns[0]] = data.columns.to_list()\n",
    "    statring_atts = graph.sum().index[np.where(graph.sum()==0)[0]]\n",
    "    data_to_file = []\n",
    "#    with open('./pc/PP/Adult_pc_DAG_{file_num}.stan'.format(file_num=file_num),'w') as file:\n",
    "    #file.write('data{\\n')\n",
    "    data_to_file.append('data{\\n')\n",
    "\n",
    "    #file.write('int<lower = 0> N;\\n')\n",
    "    data_to_file.append('int<lower = 0> N;\\n')\n",
    "    for att in graph.columns[1:]:\n",
    "        #file.write('array[N] int<lower={min_bound}, upper={max_bound}>  {x};\\n'.format(min_bound = data.min()[att], max_bound = data.max()[att], x = att))\n",
    "        if 'float' in dataset_types[np.where(data.columns==att)[0][0]]:\n",
    "            data_to_file.append('array[N] real<lower={min_bound}, upper={max_bound}>  {x};\\n'.format(min_bound = data.min()[att], max_bound = data.max()[att], x = att))\n",
    "\n",
    "        else:           \n",
    "            data_to_file.append('array[N] int<lower={min_bound}, upper={max_bound}>  {x};\\n'.format(min_bound = data.min()[att], max_bound = data.max()[att], x = att))\n",
    "    #file.write('}\\n')\n",
    "    \n",
    "        \n",
    "    data_to_file.append('}\\n')\n",
    "    #file.write('\\n')\n",
    "    data_to_file.append('\\n')\n",
    "    #file.write('transformed data {\\n')\n",
    "    data_to_file.append('transformed data {\\n')\n",
    "    #file.write('}\\n')\n",
    "    data_to_file.append('}\\n')\n",
    "    #file.write('\\n')\n",
    "    data_to_file.append('\\n')\n",
    "    #file.write('parameters {\\n')\n",
    "    data_to_file.append('parameters {\\n')\n",
    "    need_posterier=[]\n",
    "    for ind in range(graph.shape[0]):\n",
    "        for att in graph.columns[np.where(graph.iloc[ind]==1)[0]]:\n",
    "            #file.write('real {x}{y};\\n'.format(x = graph['Unnamed: 0'][ind], y = att))\n",
    "            data_to_file.append('real {x}{y};\\n'.format(x = graph['Unnamed: 0'][ind], y = att))\n",
    "\n",
    "        if graph['Unnamed: 0'][ind] not in statring_atts:\n",
    "            #file.write('real {x}0;\\n'.format(x = graph['Unnamed: 0'][ind]))\n",
    "            data_to_file.append('real {x}0;\\n'.format(x = graph['Unnamed: 0'][ind]))\n",
    "            need_posterier.append(graph['Unnamed: 0'][ind])\n",
    "\n",
    "        #file.write('\\n')\n",
    "        data_to_file.append('\\n')\n",
    "    if 0 in np.char.find(dataset_types,'float'):\n",
    "        data_to_file.append('real<lower=0> sigma_h_Sq;\\n')\n",
    "    #file.write('}\\n')\n",
    "    data_to_file.append('}\\n')\n",
    "    #file.write('\\n')\n",
    "    data_to_file.append('\\n')\n",
    "    #file.write('transformed parameters {\\n')\n",
    "    data_to_file.append('transformed parameters {\\n')\n",
    "    #file.write('}\\n')\n",
    "    if 0 in np.char.find(dataset_types,'float'):\n",
    "        data_to_file.append('real<lower=0> sigma_h;\\n')\n",
    "        data_to_file.append('sigma_h = sqrt(sigma_h_Sq);\\n')\n",
    "    data_to_file.append('}\\n')\n",
    "    #file.write('\\n')\n",
    "    data_to_file.append('\\n')\n",
    "    #file.write('model {\\n')\n",
    "    data_to_file.append('model {\\n')\n",
    "\n",
    "    for ind in range(graph.shape[0]):\n",
    "        for att in graph.columns[np.where(graph.iloc[ind]==1)[0]]:\n",
    "            #file.write('{x}{y}        ~ normal(0, 1);\\n'.format(x = graph['Unnamed: 0'][ind], y = att))\n",
    "            data_to_file.append('{x}{y}        ~ normal(0, 1);\\n'.format(x = graph['Unnamed: 0'][ind], y = att))\n",
    "        if graph['Unnamed: 0'][ind] not in statring_atts:\n",
    "            #file.write('{x}0        ~ normal(0, 1);\\n'.format(x = graph['Unnamed: 0'][ind]))\n",
    "            data_to_file.append('{x}0        ~ normal(0, 1);\\n'.format(x = graph['Unnamed: 0'][ind]))\n",
    "        #file.write('\\n')\n",
    "        data_to_file.append('\\n')\n",
    "    #file.write('for(ind in 1:N){')\n",
    "    if 0 in np.char.find(dataset_types,'float'):\n",
    "        data_to_file.append('sigma_h_Sq ~ inv_gamma(1, 1);\\n')\n",
    "        data_to_file.append('\\n')\n",
    "    data_to_file.append('for(ind in 1:N){')\n",
    "    graph_dic ={}\n",
    "    for i in graph.columns[1:]:\n",
    "        if np.where(graph[i])[0].shape[0]==0:\n",
    "            graph_dic[i]=None\n",
    "        else:\n",
    "            graph_dic[i]= graph['Unnamed: 0'][np.where(graph[i])[0]].values\n",
    "    time1 = time.time()\n",
    "    while statring_atts.shape[0] != graph['Unnamed: 0'].shape[0]:\n",
    "        if time.time() - time1>5:\n",
    "            #print('Not a DAG', file_num)\n",
    "            not_a_DAG = True\n",
    "            break\n",
    "        for att in graph_dic.keys():\n",
    "    #         print('------------')\n",
    "    #         print(att)\n",
    "    #         print(statring_atts)\n",
    "\n",
    "            if att not in statring_atts:\n",
    "                if 0 in  [1 if graph_dic[att][i] in statring_atts else 0 for i in range(graph_dic[att].shape[0])]:\n",
    "                    #print('jump')\n",
    "                    continue\n",
    "                else:\n",
    "                    string =''\n",
    "                    for i in range(graph_dic[att].shape[0]):\n",
    "                        string += '({y}{x} * {y}[ind])  +'.format(x=att, y=graph_dic[att][i])\n",
    "                    #if att == 'hours-per-week':input()\n",
    "                    if np.unique(data[att]).shape[0]==2:\n",
    "                        string = '{x}[ind] ~ bernoulli_logit('.format(x = att) + string + ' {x}0'.format(x=att)+');'\n",
    "\n",
    "                    elif 'float' in dataset_types[np.where(data.columns==att)[0][0]]:\n",
    "                        string = '{x}[ind] ~ normal('.format(x = att) + string + ' {x}0'.format(x=att)+', sigma_h);' \n",
    "                    else:    \n",
    "                        string = '{x}[ind] ~ poisson(exp('.format(x = att) + string + ' {x}0'.format(x=att)+'));'\n",
    "                    statring_atts = np.append(statring_atts,att) \n",
    "                    #file.write(string+'\\n')\n",
    "                    data_to_file.append(string+'\\n')\n",
    "    #file.write('}\\n')\n",
    "    data_to_file.append('}\\n')\n",
    "    #file.write('\\n')\n",
    "    data_to_file.append('\\n')\n",
    "    #file.write('}\\n')\n",
    "    data_to_file.append('}\\n')\n",
    "    #file.write('\\n')\n",
    "    data_to_file.append('\\n')\n",
    "    if not_a_DAG == False:\n",
    "        print('DAG ', file_num)\n",
    "        dags_num += 1\n",
    "        with open('./'+Algorithm+'/PP/Bank_'+Algorithm+'_DAG_{file_num}.stan'.format(file_num=file_num),'w') as file:\n",
    "            file.writelines(data_to_file)\n",
    "    if Algorithm == 'simy' and dags_num ==16:\n",
    "        break\n",
    "#     print('Python code -----------------')\n",
    "#     for edge in graph.sum().index[np.where(graph.sum()==0)[0]]:\n",
    "#         print('{edge}  = df[\\'{edge}\\'].values'.format(edge = edge))\n",
    "\n",
    "#     statring_atts = graph.sum().index[np.where(graph.sum()==0)[0]]\n",
    "#     time1 = time.time()\n",
    "#     while statring_atts.shape[0] != graph['Unnamed: 0'].shape[0]:\n",
    "#         if time.time() - time1>60:\n",
    "#             break\n",
    "#         for att in graph_dic.keys():\n",
    "#     #         print('------------')\n",
    "#     #         print(att)\n",
    "#     #         print(statring_atts)\n",
    "\n",
    "#             if att not in statring_atts:\n",
    "\n",
    "#                 if 0 in  [1 if graph_dic[att][i] in statring_atts else 0 for i in range(graph_dic[att].shape[0])]:\n",
    "#                     #print('jump')\n",
    "#                     continue\n",
    "#                 else:\n",
    "\n",
    "#                     if np.unique(data[att]).shape[0]==2:\n",
    "#                         string1 ='('\n",
    "#                         for i in range(graph_dic[att].shape[0]):\n",
    "#                             string1 += '(edges[\\'{y}{x}\\'] * {y})  +'.format(x=att, y =graph_dic[att][i]) \n",
    "#                         string1 = '{edge}_logits = '.format(edge=att)+ string1  +  ' edges[\\'{x}0\\'] )'.format(x=att)\n",
    "#                         string2 = '{edge} =  tfb.distributions.Bernoulli(logits={edge}_logits).sample().numpy()'.format(edge=att)\n",
    "\n",
    "#                         #print('\\n')\n",
    "#                     else:    \n",
    "#                         string1 ='tf.exp('\n",
    "#                         for i in range(graph_dic[att].shape[0]):\n",
    "#                             string1 += '(edges[\\'{y}{x}\\'] * {y})  +'.format(x=att, y =graph_dic[att][i]) \n",
    "#                         string1 = '{edge}_logits = '.format(edge=att)+ string1  +  ' edges[\\'{x}0\\'] )'.format(x=att)\n",
    "#                         string2 = '{edge} =  tfb.distributions.Poisson(rate={edge}_logits).sample().numpy()'.format(edge=att)\n",
    "\n",
    "#                         #print('\\n')\n",
    "#                     print(string1)\n",
    "#                     print(string2)\n",
    "#                     print('\\n')\n",
    "#                     statring_atts = np.append(statring_atts,att) \n",
    "#     print('new_df = pd.DataFrame(columns = df.columns)')\n",
    "#     for feat in graph.columns[1:]:\n",
    "#         print('new_df[\\'{edge}\\']  = {edge}'.format(edge=feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf62d281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>LSAT</th>\n",
       "      <th>UGPA</th>\n",
       "      <th>first_pf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21786</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21787</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21788</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21789</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21790</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21791 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       race  sex  LSAT  UGPA  first_pf\n",
       "0         7    0  39.0   3.1         1\n",
       "1         7    0  36.0   3.0         1\n",
       "2         7    1  30.0   3.1         1\n",
       "3         3    1  39.0   2.2         1\n",
       "4         7    0  37.0   3.4         1\n",
       "...     ...  ...   ...   ...       ...\n",
       "21786     7    1  33.0   4.0         1\n",
       "21787     7    0  38.0   3.7         0\n",
       "21788     7    0  36.0   4.0         1\n",
       "21789     7    1  31.0   2.9         1\n",
       "21790     7    1  28.0   3.1         1\n",
       "\n",
       "[21791 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7139542e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
