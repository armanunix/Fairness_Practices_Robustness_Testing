{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129de982",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "Algorithm = 'simy'\n",
    "\n",
    "data = pd.read_csv('../subjects/datasets/students-processed_2')\n",
    "dataset_types = [str(data[i].dtype) for i in data.columns]\n",
    "for file_num in range(1,500):\n",
    "    not_a_DAG = False\n",
    "    graph = pd.read_csv('./'+Algorithm+'/DAGs/Student_'+Algorithm+'_DAG_{file_num}.csv'.format(file_num=file_num))\n",
    "    graph.columns =  [graph.columns[0]]+ data.columns.to_list()\n",
    "    graph[graph.columns[0]] = data.columns.to_list()\n",
    "    statring_atts = graph.sum().index[np.where(graph.sum()==0)[0]]\n",
    "    data_to_file = []\n",
    "#    with open('./pc/PP/Adult_pc_DAG_{file_num}.stan'.format(file_num=file_num),'w') as file:\n",
    "    #file.write('data{\\n')\n",
    "    data_to_file.append('data{\\n')\n",
    "\n",
    "    #file.write('int<lower = 0> N;\\n')\n",
    "    data_to_file.append('int<lower = 0> N;\\n')\n",
    "    for att in graph.columns[1:]:\n",
    "        #file.write('array[N] int<lower={min_bound}, upper={max_bound}>  {x};\\n'.format(min_bound = data.min()[att], max_bound = data.max()[att], x = att))\n",
    "        if 'float' in dataset_types[np.where(data.columns==att)[0][0]]:\n",
    "            data_to_file.append('array[N] real<lower={min_bound}, upper={max_bound}>  {x};\\n'.format(min_bound = data.min()[att], max_bound = data.max()[att], x = att))\n",
    "\n",
    "        else:           \n",
    "            data_to_file.append('array[N] int<lower={min_bound}, upper={max_bound}>  {x};\\n'.format(min_bound = data.min()[att], max_bound = data.max()[att], x = att))\n",
    "    #file.write('}\\n')\n",
    "    \n",
    "        \n",
    "    data_to_file.append('}\\n')\n",
    "    #file.write('\\n')\n",
    "    data_to_file.append('\\n')\n",
    "    #file.write('transformed data {\\n')\n",
    "    data_to_file.append('transformed data {\\n')\n",
    "    #file.write('}\\n')\n",
    "    data_to_file.append('}\\n')\n",
    "    #file.write('\\n')\n",
    "    data_to_file.append('\\n')\n",
    "    #file.write('parameters {\\n')\n",
    "    data_to_file.append('parameters {\\n')\n",
    "    need_posterier=[]\n",
    "    for ind in range(graph.shape[0]):\n",
    "        for att in graph.columns[np.where(graph.iloc[ind]==1)[0]]:\n",
    "            #file.write('real {x}{y};\\n'.format(x = graph['Unnamed: 0'][ind], y = att))\n",
    "            data_to_file.append('real {x}{y};\\n'.format(x = graph['Unnamed: 0'][ind], y = att))\n",
    "\n",
    "        if graph['Unnamed: 0'][ind] not in statring_atts:\n",
    "            #file.write('real {x}0;\\n'.format(x = graph['Unnamed: 0'][ind]))\n",
    "            data_to_file.append('real {x}0;\\n'.format(x = graph['Unnamed: 0'][ind]))\n",
    "            need_posterier.append(graph['Unnamed: 0'][ind])\n",
    "\n",
    "        #file.write('\\n')\n",
    "        data_to_file.append('\\n')\n",
    "    if 0 in np.char.find(dataset_types,'float'):\n",
    "        data_to_file.append('real<lower=0> sigma_h_Sq;\\n')\n",
    "    #file.write('}\\n')\n",
    "    data_to_file.append('}\\n')\n",
    "    #file.write('\\n')\n",
    "    data_to_file.append('\\n')\n",
    "    #file.write('transformed parameters {\\n')\n",
    "    data_to_file.append('transformed parameters {\\n')\n",
    "    #file.write('}\\n')\n",
    "    if 0 in np.char.find(dataset_types,'float'):\n",
    "        data_to_file.append('real<lower=0> sigma_h;\\n')\n",
    "        data_to_file.append('sigma_h = sqrt(sigma_h_Sq);\\n')\n",
    "    data_to_file.append('}\\n')\n",
    "    #file.write('\\n')\n",
    "    data_to_file.append('\\n')\n",
    "    #file.write('model {\\n')\n",
    "    data_to_file.append('model {\\n')\n",
    "\n",
    "    for ind in range(graph.shape[0]):\n",
    "        for att in graph.columns[np.where(graph.iloc[ind]==1)[0]]:\n",
    "            #file.write('{x}{y}        ~ normal(0, 1);\\n'.format(x = graph['Unnamed: 0'][ind], y = att))\n",
    "            data_to_file.append('{x}{y}        ~ normal(0, 1);\\n'.format(x = graph['Unnamed: 0'][ind], y = att))\n",
    "        if graph['Unnamed: 0'][ind] not in statring_atts:\n",
    "            #file.write('{x}0        ~ normal(0, 1);\\n'.format(x = graph['Unnamed: 0'][ind]))\n",
    "            data_to_file.append('{x}0        ~ normal(0, 1);\\n'.format(x = graph['Unnamed: 0'][ind]))\n",
    "        #file.write('\\n')\n",
    "        data_to_file.append('\\n')\n",
    "    #file.write('for(ind in 1:N){')\n",
    "    if 0 in np.char.find(dataset_types,'float'):\n",
    "        data_to_file.append('sigma_h_Sq ~ inv_gamma(1, 1);\\n')\n",
    "        data_to_file.append('\\n')\n",
    "    data_to_file.append('for(ind in 1:N){')\n",
    "    graph_dic ={}\n",
    "    for i in graph.columns[1:]:\n",
    "        if np.where(graph[i])[0].shape[0]==0:\n",
    "            graph_dic[i]=None\n",
    "        else:\n",
    "            graph_dic[i]= graph['Unnamed: 0'][np.where(graph[i])[0]].values\n",
    "    time1 = time.time()\n",
    "    while statring_atts.shape[0] != graph['Unnamed: 0'].shape[0]:\n",
    "        if time.time() - time1>2:\n",
    "            #print('Not a DAG', file_num)\n",
    "            not_a_DAG = True\n",
    "            break\n",
    "        for att in graph_dic.keys():\n",
    "    #         print('------------')\n",
    "    #         print(att)\n",
    "    #         print(statring_atts)\n",
    "\n",
    "            if att not in statring_atts:\n",
    "                if 0 in  [1 if graph_dic[att][i] in statring_atts else 0 for i in range(graph_dic[att].shape[0])]:\n",
    "                    #print('jump')\n",
    "                    continue\n",
    "                else:\n",
    "                    string =''\n",
    "                    for i in range(graph_dic[att].shape[0]):\n",
    "                        string += '({y}{x} * {y}[ind])  +'.format(x=att, y=graph_dic[att][i])\n",
    "                    #if att == 'hours-per-week':input()\n",
    "                    if np.unique(data[att]).shape[0]==2:\n",
    "                        string = '{x}[ind] ~ bernoulli_logit('.format(x = att) + string + ' {x}0'.format(x=att)+');'\n",
    "\n",
    "                    elif 'float' in dataset_types[np.where(data.columns==att)[0][0]]:\n",
    "                        string = '{x}[ind] ~ normal('.format(x = att) + string + ' {x}0'.format(x=att)+', sigma_h);' \n",
    "                    else:    \n",
    "                        string = '{x}[ind] ~ poisson(exp('.format(x = att) + string + ' {x}0'.format(x=att)+'));'\n",
    "                    statring_atts = np.append(statring_atts,att) \n",
    "                    #file.write(string+'\\n')\n",
    "                    data_to_file.append(string+'\\n')\n",
    "    #file.write('}\\n')\n",
    "    data_to_file.append('}\\n')\n",
    "    #file.write('\\n')\n",
    "    data_to_file.append('\\n')\n",
    "    #file.write('}\\n')\n",
    "    data_to_file.append('}\\n')\n",
    "    #file.write('\\n')\n",
    "    data_to_file.append('\\n')\n",
    "    if not_a_DAG == False:\n",
    "        print('DAG ', file_num)\n",
    "        with open('./'+Algorithm+'/PP/Student_'+Algorithm+'_DAG_{file_num}.stan'.format(file_num=file_num),'w') as file:\n",
    "            file.writelines(data_to_file)\n",
    "#     print('Python code -----------------')\n",
    "#     for edge in graph.sum().index[np.where(graph.sum()==0)[0]]:\n",
    "#         print('{edge}  = df[\\'{edge}\\'].values'.format(edge = edge))\n",
    "\n",
    "#     statring_atts = graph.sum().index[np.where(graph.sum()==0)[0]]\n",
    "#     time1 = time.time()\n",
    "#     while statring_atts.shape[0] != graph['Unnamed: 0'].shape[0]:\n",
    "#         if time.time() - time1>60:\n",
    "#             break\n",
    "#         for att in graph_dic.keys():\n",
    "#     #         print('------------')\n",
    "#     #         print(att)\n",
    "#     #         print(statring_atts)\n",
    "\n",
    "#             if att not in statring_atts:\n",
    "\n",
    "#                 if 0 in  [1 if graph_dic[att][i] in statring_atts else 0 for i in range(graph_dic[att].shape[0])]:\n",
    "#                     #print('jump')\n",
    "#                     continue\n",
    "#                 else:\n",
    "\n",
    "#                     if np.unique(data[att]).shape[0]==2:\n",
    "#                         string1 ='('\n",
    "#                         for i in range(graph_dic[att].shape[0]):\n",
    "#                             string1 += '(edges[\\'{y}{x}\\'] * {y})  +'.format(x=att, y =graph_dic[att][i]) \n",
    "#                         string1 = '{edge}_logits = '.format(edge=att)+ string1  +  ' edges[\\'{x}0\\'] )'.format(x=att)\n",
    "#                         string2 = '{edge} =  tfb.distributions.Bernoulli(logits={edge}_logits).sample().numpy()'.format(edge=att)\n",
    "\n",
    "#                         #print('\\n')\n",
    "#                     else:    \n",
    "#                         string1 ='tf.exp('\n",
    "#                         for i in range(graph_dic[att].shape[0]):\n",
    "#                             string1 += '(edges[\\'{y}{x}\\'] * {y})  +'.format(x=att, y =graph_dic[att][i]) \n",
    "#                         string1 = '{edge}_logits = '.format(edge=att)+ string1  +  ' edges[\\'{x}0\\'] )'.format(x=att)\n",
    "#                         string2 = '{edge} =  tfb.distributions.Poisson(rate={edge}_logits).sample().numpy()'.format(edge=att)\n",
    "\n",
    "#                         #print('\\n')\n",
    "#                     print(string1)\n",
    "#                     print(string2)\n",
    "#                     print('\\n')\n",
    "#                     statring_atts = np.append(statring_atts,att) \n",
    "#     print('new_df = pd.DataFrame(columns = df.columns)')\n",
    "#     for feat in graph.columns[1:]:\n",
    "#         print('new_df[\\'{edge}\\']  = {edge}'.format(edge=feat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
