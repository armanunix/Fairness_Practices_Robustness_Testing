{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c555ec8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 02:07:33.612188: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-31 02:07:34.159797: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm pc\n",
      "WARNING:tensorflow:From /home/vmonjezi/.virtualenvs/RISC_LAB/lib/python3.8/site-packages/tensorflow_probability/python/internal/batched_rejection_sampler.py:102: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 02:07:36.423036: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.423307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.439438: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.439728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.439907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.440076: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.551737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.552003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.552189: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.552365: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.552534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.552703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.560726: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.560945: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.561128: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.561315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.561489: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.561631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22463 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2024-07-31 02:07:36.561921: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-31 02:07:36.562054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22463 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:61:00.0, compute capability: 8.6\n",
      "2024-07-31 02:07:36.797675: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'shape' with dtype int32 and shape [1]\n",
      "\t [[{{node shape}}]]\n",
      "2024-07-31 02:07:36.800857: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'shape' with dtype int32 and shape [1]\n",
      "\t [[{{node shape}}]]\n",
      "2024-07-31 02:07:36.820525: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'poisson_noncpu/batched_las_vegas_algorithm/while/uniform/stateless_random_uniform/StatelessRandomUniformV2/poisson_noncpu/concat' with dtype int32 and shape [2]\n",
      "\t [[{{node poisson_noncpu/batched_las_vegas_algorithm/while/uniform/stateless_random_uniform/StatelessRandomUniformV2/poisson_noncpu/concat}}]]\n",
      "2024-07-31 02:07:36.820598: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'poisson_noncpu/batched_las_vegas_algorithm/while/uniform/stateless_random_uniform/StatelessRandomUniformV2/poisson_noncpu/concat' with dtype int32 and shape [2]\n",
      "\t [[{{node poisson_noncpu/batched_las_vegas_algorithm/while/uniform/stateless_random_uniform/StatelessRandomUniformV2/poisson_noncpu/concat}}]]\n",
      "2024-07-31 02:07:36.823600: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'poisson_noncpu/batched_las_vegas_algorithm/while/uniform/stateless_random_uniform/StatelessRandomUniformV2/poisson_noncpu/concat' with dtype int32 and shape [2]\n",
      "\t [[{{node poisson_noncpu/batched_las_vegas_algorithm/while/uniform/stateless_random_uniform/StatelessRandomUniformV2/poisson_noncpu/concat}}]]\n",
      "2024-07-31 02:07:36.823657: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'poisson_noncpu/batched_las_vegas_algorithm/while/uniform/stateless_random_uniform/StatelessRandomUniformV2/poisson_noncpu/concat' with dtype int32 and shape [2]\n",
      "\t [[{{node poisson_noncpu/batched_las_vegas_algorithm/while/uniform/stateless_random_uniform/StatelessRandomUniformV2/poisson_noncpu/concat}}]]\n",
      "2024-07-31 02:07:36.846839: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'shape' with dtype int32 and shape [1]\n",
      "\t [[{{node shape}}]]\n",
      "2024-07-31 02:07:36.847550: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'shape' with dtype int32 and shape [1]\n",
      "\t [[{{node shape}}]]\n",
      "2024-07-31 02:07:36.848180: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'shape' with dtype int32 and shape [1]\n",
      "\t [[{{node shape}}]]\n",
      "2024-07-31 02:07:36.855200: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'poisson_noncpu/while/uniform/stateless_random_uniform/StatelessRandomUniformV2/poisson_noncpu/concat' with dtype int32 and shape [2]\n",
      "\t [[{{node poisson_noncpu/while/uniform/stateless_random_uniform/StatelessRandomUniformV2/poisson_noncpu/concat}}]]\n",
      "2024-07-31 02:07:36.855260: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'poisson_noncpu/while/uniform/stateless_random_uniform/StatelessRandomUniformV2/poisson_noncpu/concat' with dtype int32 and shape [2]\n",
      "\t [[{{node poisson_noncpu/while/uniform/stateless_random_uniform/StatelessRandomUniformV2/poisson_noncpu/concat}}]]\n",
      "2024-07-31 02:07:36.872647: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'shape' with dtype int32 and shape [1]\n",
      "\t [[{{node shape}}]]\n",
      "2024-07-31 02:07:36.875307: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'shape' with dtype int32 and shape [1]\n",
      "\t [[{{node shape}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mahalanobis distances cannot be calculated with singular covariance matrix\n",
      "Singular matrix\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vmonjezi/.virtualenvs/RISC_LAB/lib/python3.8/site-packages/mahalanobis/__init__.py\", line 115, in _invert_cov_matrix\n",
      "    inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
      "  File \"<__array_function__ internals>\", line 180, in inv\n",
      "  File \"/home/vmonjezi/.virtualenvs/RISC_LAB/lib/python3.8/site-packages/numpy/linalg/linalg.py\", line 552, in inv\n",
      "    ainv = _umath_linalg.inv(a, signature=signature, extobj=extobj)\n",
      "  File \"/home/vmonjezi/.virtualenvs/RISC_LAB/lib/python3.8/site-packages/numpy/linalg/linalg.py\", line 89, in _raise_linalgerror_singular\n",
      "    raise LinAlgError(\"Singular matrix\")\n",
      "numpy.linalg.LinAlgError: Singular matrix\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 215\u001b[0m\n\u001b[1;32m    204\u001b[0m                 final_df, succ_rate \u001b[38;5;241m=\u001b[39m generate_dataset_RND(df, graph, rnd_edges_list, ave_dist, KMean\u001b[38;5;241m.\u001b[39mcluster_centers_ ,sens_index, priv_group, unpriv_group)\n\u001b[1;32m    206\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m final_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m#                     X_rnd = final_df.to_numpy()[:,:-1]\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m#                     dist = euclidean_distances(X_rnd, KMean.cluster_centers_)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m#                     distance_list = tree.query(X_gen, k=1)[0]\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m#                     distance_avg = round(distance_list.mean(),3)\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m                     distance_avg  \u001b[38;5;241m=\u001b[39m \u001b[43mmahND\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m#                     input(dist)\u001b[39;00m\n\u001b[1;32m    217\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m                     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/RISC_LAB/lib/python3.8/site-packages/mahalanobis/__init__.py:483\u001b[0m, in \u001b[0;36mMahalanobisND.calc_distances\u001b[0;34m(self, new_input)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m     new_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(new_input, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_columns, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 483\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_dists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/RISC_LAB/lib/python3.8/site-packages/mahalanobis/__init__.py:144\u001b[0m, in \u001b[0;36mMahalanobisBenchmark._calculate_dists\u001b[0;34m(self, input_array)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_calculate_dists\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_array):  \u001b[38;5;66;03m# TODO: Write unit tests\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the calculated mean and covariance matrix for calculating the Mahalanobis distances\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    for each observation in the inbound array.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    ShapeError : if the inbound array does not match the dimensionality of the problem\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inv_cov_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invert_cov_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cov_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimensionality:\n\u001b[1;32m    147\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDimensions of passed array do not match calibration dimensions of Mahalanobis object\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/RISC_LAB/lib/python3.8/site-packages/mahalanobis/__init__.py:122\u001b[0m, in \u001b[0;36mMahalanobisBenchmark._invert_cov_matrix\u001b[0;34m(self, cov_matrix)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39merror(msg)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39merror(e, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inv_cov_matrix\n",
      "File \u001b[0;32m~/.virtualenvs/RISC_LAB/lib/python3.8/site-packages/mahalanobis/__init__.py:115\u001b[0m, in \u001b[0;36mMahalanobisBenchmark._invert_cov_matrix\u001b[0;34m(self, cov_matrix)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the inverse of the covariance matrix\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     inv_cov_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# TODO: look into possible pseudo-inverses for the case of non-invertible covariance matrices.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# https://en.wikipedia.org/wiki/Generalized_inverse#Reflexive_generalized_inverse\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mLinAlgError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.virtualenvs/RISC_LAB/lib/python3.8/site-packages/numpy/linalg/linalg.py:552\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    550\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    551\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 552\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/.virtualenvs/RISC_LAB/lib/python3.8/site-packages/numpy/linalg/linalg.py:89\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "sys.path.append(\"./subjects/\")\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import random, math\n",
    "import tensorflow_probability as tfb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics.pairwise import  euclidean_distances\n",
    "import glob\n",
    "import re\n",
    "from sklearn.neighbors import KDTree\n",
    "from Utils_Functions import generate_dataset, eod\n",
    "import mahalanobis\n",
    "def generate_dataset_RND(data, graph, edges, ave_dist, centroids,sens_index, priv_group, unpriv_group):\n",
    "    global final_df,dist\n",
    "    dataset_types = [str(data[i].dtype) for i in data.columns]\n",
    "    succ_generated = 0\n",
    "    generation_coef = 10\n",
    "    graph_dic ={}\n",
    "    for i in graph.columns[1:]:\n",
    "        if np.where(graph[i])[0].shape[0]==0:\n",
    "            graph_dic[i]=None\n",
    "        else:\n",
    "            graph_dic[i]= graph['Unnamed: 0'][np.where(graph[i])[0]].values\n",
    "\n",
    "    final_df = pd.DataFrame(columns = data.columns) \n",
    "    trial = 0\n",
    "    not_interesting = False\n",
    "    while final_df.shape[0]<data.shape[0]/2:\n",
    "\n",
    "        if trial > 20:\n",
    "            break\n",
    "            \n",
    "        df_new_dic ={}\n",
    "        for edge in graph.sum().index[np.where(graph.sum()==0)[0]]:\n",
    "            df_new_dic[edge] = np.random.choice(np.unique(data[edge]), size = data.shape[0]*generation_coef) \n",
    "\n",
    "        statring_atts = graph.sum().index[np.where(graph.sum()==0)[0]]\n",
    "        \n",
    "        while statring_atts.shape[0] != graph['Unnamed: 0'].shape[0]:\n",
    "            \n",
    "            for att in graph_dic.keys():\n",
    "                if att not in statring_atts:\n",
    "                    if 0 in  [1 if graph_dic[att][i] in statring_atts else 0 for i in range(graph_dic[att].shape[0])]:\n",
    "\n",
    "                        continue\n",
    "                    else:\n",
    "                        edge_logits = 0\n",
    "                        \n",
    "                        for cause in graph_dic[att]:\n",
    "                            edge_logits += (edges[cause+att] * df_new_dic[cause])\n",
    "                        if np.unique(data[att]).shape[0]==2:\n",
    "                            df_new_dic[att] =  tfb.distributions.Bernoulli(logits=edge_logits + edges[att+'0'] ).sample().numpy()\n",
    "                        elif 'float' in dataset_types[np.where(data.columns==att)[0][0]]:\n",
    "\n",
    "                            df_new_dic[att] =  tfb.distributions.Normal(loc=(edge_logits+ edges[att+'0']), scale= edges['sigma_h']).sample().numpy()\n",
    "                        \n",
    "                        else:    \n",
    "                            df_new_dic[att] =  tfb.distributions.Poisson(rate=tf.exp(edge_logits+ edges[att+'0']) ).sample().numpy()  \n",
    "\n",
    "                        statring_atts = np.append(statring_atts,att) \n",
    "\n",
    "        new_df = pd.DataFrame(columns = data.columns)\n",
    "        for col in new_df.columns:\n",
    "            new_df[col] = df_new_dic[col]\n",
    "            \n",
    "        ind_inf = np.unique(np.where(new_df>data.max())[0])\n",
    "        new_df.drop(ind_inf,axis=0,inplace=True)\n",
    "#         new_df = new_df.replace([np.inf], None)\n",
    "#         new_df.dropna(inplace=True)\n",
    "        \n",
    "        if new_df.shape[0]<1:\n",
    "            trial += 1\n",
    "            continue\n",
    "#         print('new samples', new_df.shape[0])\n",
    "        final_df = pd.concat([final_df,new_df]).reset_index(drop=True)\n",
    "#         print('new samples', new_df.shape[0])\n",
    "#         print('final samples', final_df.shape[0])\n",
    "        trial += 1\n",
    "        \n",
    "        X2 = new_df.to_numpy()[:,:-1]\n",
    "        Y2 = new_df.to_numpy()[:,-1]\n",
    "        dist = euclidean_distances(X2, centroids)\n",
    "        \n",
    "        succ_generated += new_df.iloc[np.where((ave_dist>=dist).sum(1)>0)].shape[0]\n",
    "#         print(trial, succ_generated, trial *  data.shape[0]*generation_coef,  )\n",
    "    succ_rate = succ_generated/( trial *  data.shape[0]*generation_coef) \n",
    "#     print(final_df, succ_rate)\n",
    "#     input()\n",
    "#     X2 = new_df.to_numpy()[:,:-1]\n",
    "#     Y2 = new_df.to_numpy()[:,-1]\n",
    "#     dist = euclidean_distances(X2, centroids)\n",
    "    return final_df, succ_rate\n",
    "\n",
    "\n",
    "for dataset in [ 'Adult']:#, 'Law', 'Student']:\n",
    "\n",
    "    if dataset == 'Adult':\n",
    "        sens_index = 7\n",
    "        priv_group = 1\n",
    "        unpriv_group = 0\n",
    "        data_file_name = 'adult_org-Copy1.csv'\n",
    "    if dataset == 'Compas':\n",
    "        sens_index = 1\n",
    "        priv_group = 1\n",
    "        unpriv_group = 0\n",
    "        data_file_name = 'compas-Copy1'\n",
    "    if dataset == 'Bank':\n",
    "        sens_index = 0\n",
    "        priv_group = 5\n",
    "        unpriv_group = 3\n",
    "        data_file_name = 'bank'\n",
    "    if dataset == 'Heart':\n",
    "        sens_index = 0\n",
    "        priv_group = 1\n",
    "        unpriv_group = 0 \n",
    "        data_file_name = 'heart_processed_1'\n",
    "    if dataset == 'Law':\n",
    "        sens_index = 1\n",
    "        priv_group = 1\n",
    "        unpriv_group = 0\n",
    "        data_file_name = 'law.csv'\n",
    "\n",
    "    if dataset == 'Student':\n",
    "        sens_index = 0\n",
    "        priv_group = 1\n",
    "        unpriv_group = 0  \n",
    "        data_file_name = 'students-processed_2'\n",
    "\n",
    "\n",
    "\n",
    "    df = pd.read_csv('./subjects/datasets/'+data_file_name)\n",
    "    df = df.drop_duplicates()\n",
    "    X1 = df.to_numpy()[:,:-1]\n",
    "    Y1 = df.to_numpy()[:,-1]\n",
    "    mahND = mahalanobis.MahalanobisND(df.to_numpy().astype(float),10 )\n",
    "    num_cluster = 100\n",
    "    try :\n",
    "        with open('./'+dataset+'_Analysis/Kmean/KMean_{clus}.pkl'.format(clus=num_cluster), 'rb') as f:\n",
    "            KMean = pickle.load(f)\n",
    "    except:\n",
    "        KMean = KMeans(n_clusters=num_cluster)\n",
    "        KMean.fit(X1)\n",
    "        with open('./'+dataset+'_Analysis/Kmean/KMean_{clus}.pkl'.format(clus=num_cluster),'wb') as f:\n",
    "            pickle.dump(KMean,f)\n",
    "\n",
    "    ave_dist =[] \n",
    "    for i in range(KMean.n_clusters):\n",
    "        mean_dist = euclidean_distances(X1[np.where(KMean.labels_==[i])],[KMean.cluster_centers_[i]]).mean()\n",
    "        std_dist = euclidean_distances(X1[np.where(KMean.labels_==[i])],[KMean.cluster_centers_[i]]).std()\n",
    "        if dataset == 'Heart':\n",
    "            ave_dist.append(mean_dist+ (3 * std_dist))\n",
    "        elif dataset == 'Compas':\n",
    "            ave_dist.append(mean_dist+ (1 * std_dist))\n",
    "        elif dataset == 'Student':\n",
    "            ave_dist.append(mean_dist+ (1 * std_dist))\n",
    "        else:\n",
    "            ave_dist.append(mean_dist+(2 * std_dist))\n",
    "    succ_rate_list =[]\n",
    "    for Algorithm in ['pc','ges','simy']:\n",
    "        print('Algorithm', Algorithm)\n",
    "\n",
    "        for edge_list_filename in glob.glob('./'+dataset+'_Analysis/'+Algorithm+'/PP/*.csv'):\n",
    "#             print(edge_list_filename)\n",
    "            file_num = int(re.findall(r'\\d+', edge_list_filename)[0])\n",
    "\n",
    "        #     if file_num in [5,7,10,12]:\n",
    "        #         continue\n",
    "\n",
    "            try:\n",
    "                graph_filename = './'+dataset+'_Analysis/'+Algorithm+'/DAGs/'+dataset+'_'+Algorithm+'_DAG_{file_num}.csv'.format(file_num=file_num)\n",
    "                graph = pd.read_csv(graph_filename)\n",
    "\n",
    "\n",
    "                #edge_list_filename = './'+dataset+'_Analysis/'+Algorithm+'/PP/'+dataset+'_'+Algorithm+'_pp_{file_num}.csv'.format(file_num=file_num)\n",
    "                edges_list = pd.read_csv(edge_list_filename)\n",
    "\n",
    "                if dataset=='Bank' and Algorithm=='simy':\n",
    "                    graph.columns = [i.replace('1','') for i in graph.columns]\n",
    "                    graph[graph.columns[0]] = [i.replace('1','') for i in graph[graph.columns[0]]]\n",
    "                    edges_list.columns = [i.replace('1','') for i in edges_list.columns]\n",
    "                edges_list = edges_list[edges_list.columns[1:-1]].mean()\n",
    "\n",
    "            except:\n",
    "                print('Not a DAG! ',file_num)\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "                #ave_dist.append(euclidean_distances(X1[np.where(KMean.labels_==[i])],[KMean.cluster_centers_[i]]).max())\n",
    "            metrics_temp=[]\n",
    "            for i in range(1):\n",
    "                rnd_edges_list = tfb.distributions.Normal(0,1).sample(edges_list.shape[0]).numpy()\n",
    "                rnd_edges_list = pd.Series(rnd_edges_list, index=edges_list.index).astype('float64')\n",
    "#                 rnd_edges_list = pd.Series([tfb.distributions.Normal(0,1).sample(1).numpy()[0]]*edges_list.shape[0], index=edges_list.index).astype('float64')\n",
    "                final_df, succ_rate = generate_dataset_RND(df, graph, rnd_edges_list, ave_dist, KMean.cluster_centers_ ,sens_index, priv_group, unpriv_group)\n",
    "   \n",
    "                if final_df.shape[0]>0:\n",
    "#                     X_rnd = final_df.to_numpy()[:,:-1]\n",
    "#                     dist = euclidean_distances(X_rnd, KMean.cluster_centers_)\n",
    "#                     X_org = df.to_numpy()[:,:-1]\n",
    "#                     X_gen = final_df.to_numpy()[:,:-1]\n",
    "#                     tree = KDTree(X_org)\n",
    "#                     distance_list = tree.query(X_gen, k=1)[0]\n",
    "#                     distance_avg = round(distance_list.mean(),3)\n",
    "                    \n",
    "                    distance_avg  = mahND.calc_distances(final_df.to_numpy().astype(float)).mean()\n",
    "#                     input(dist)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                metrics_temp.append([succ_rate,distance_avg])\n",
    "    #     succ_rate_list.append([Algorithm,file_num,round(succ_rate,3),distance_avg,distance_std])\n",
    "\n",
    "\n",
    "            succ_rate_list.append(np.mean(metrics_temp,axis=0))\n",
    "    input()\n",
    "    print(f'{dataset} -> ${round(np.mean(succ_rate_list, axis=0)[0],4)}$ & ${round(np.std(succ_rate_list, axis=0)[0],4)}$ & ${round(np.min(succ_rate_list, axis=0)[0],4)}$ & ${round(np.max(succ_rate_list, axis=0)[0],4)}$ & ${round(np.mean(succ_rate_list, axis=0)[1],2)}$')\n",
    "    \n",
    "    #     print('Success rate DAG ', Algorithm,'-> Succ_avg = ', round(np.mean(succ_rate_list, axis=0)[0],3),' Dis avg= ', np.mean(succ_rate_list, axis=0)[1])\n",
    "    np.save('./'+dataset+'_Analysis/RQ1_RND/'+dataset+'_RQ1_results_RND_mahdis.npy',succ_rate_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bfcdf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61563260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
